{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input blog link: https://medium.com/@jainashish.079/build-llm-agent-combining-reasoning-and-action-react-framework-using-langchain-379a89a7e881"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "\n",
    "from dotenv import find_dotenv, load_dotenv, dotenv_values\n",
    "load_dotenv('../.env.secret')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "# load text\n",
    "loader = TextLoader('blog.txt')\n",
    "document = loader.load()\n",
    "\n",
    "# split documents into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50)\n",
    "\n",
    "documents = text_splitter.split_documents(document)\n",
    "print(len(documents))\n",
    "\n",
    "# Embedding text and storing it in vectore store\n",
    "vector_db = Chroma.from_documents(documents, OpenAIEmbeddings(), persist_directory=\"./chroma_db_blog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'What are the key findings of the latest research on quantum computing published in 2024'\n",
    "llm = ChatOpenAI(temperature=0)\n",
    "prompt = ChatPromptTemplate.from_template(template=query)\n",
    "chain = prompt | llm\n",
    "result = chain.invoke(input={\"input\": query})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Breakthrough in error correction: Researchers have made significant progress in developing error correction techniques for quantum computers, which is crucial for overcoming the inherent fragility of quantum systems.\n",
      "\n",
      "2. Scalability: The latest research has shown promising results in scaling up quantum computing systems, with the potential to handle larger and more complex problems.\n",
      "\n",
      "3. Quantum supremacy: There have been reports of achieving quantum supremacy in certain tasks, demonstrating the superiority of quantum computers over classical computers in specific applications.\n",
      "\n",
      "4. Quantum algorithms: New quantum algorithms have been developed that show improved performance compared to classical algorithms, opening up new possibilities for solving complex problems efficiently.\n",
      "\n",
      "5. Quantum networking: Progress has been made in developing quantum networks that can securely transmit information over long distances, paving the way for a quantum internet.\n",
      "\n",
      "6. Quantum machine learning: Researchers have explored the intersection of quantum computing and machine learning, leading to the development of novel algorithms that can outperform classical machine learning techniques.\n",
      "\n",
      "7. Quantum simulation: Quantum computers have been used to simulate complex quantum systems, providing insights into fundamental physics and enabling the study of materials at the quantum level.\n",
      "\n",
      "Overall, the latest research on quantum computing in 2024 has shown significant advancements in various areas, bringing us closer to realizing the full potential of quantum technology.\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG using langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"\"\"Answer any use questions based solely on the context below:\n",
    "\n",
    "    <context>\n",
    "    {context}\n",
    "    </context>\"\"\"),\n",
    "    (\"placeholder\", \"{chat_history}\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "retriever = vector_db.as_retriever()\n",
    "\n",
    "combine_docs_chain = create_stuff_documents_chain(llm, qa_prompt)\n",
    "retrival_chain = create_retrieval_chain(\n",
    "    retriever=retriever, combine_docs_chain=combine_docs_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': 'explain me the example given in the blog', 'context': [Document(metadata={'source': 'blog.txt'}, page_content='as the one-shot example. By structuring the examples in this way, we are essentially teaching the model how to reason through the task to reach a solution. The model now correctly determines that nine apples are left. Thinking through the problem has helped the model come to the correct answer. We can use chain of thought prompting to help LLMs improve their reasoning for other types of problems.'), Document(metadata={'source': 'blog.txt'}, page_content='ReAct Prompt Template\\nWe can come up with standard template for ReAct for queries. We are asking question with LLM inside the prompt with instruction and some examples.\\n\\n\\nReAct Execution Flow\\nModel can start its execution by learning from the given example. It can start its process by taking first thought.\\n\\nThought1 I need to search Amitabh Bachchan and Shahrukh Khan, find their profession, then find the profession they have in common.\\n\\nAction1 Search[Amitabh Bachchan]'), Document(metadata={'source': 'blog.txt'}, page_content='from langchain.agents.react.base import DocstoreExplorer\\nfrom langchain.docstore import Wikipedia\\ndocstore = DocstoreExplorer(Wikipedia())\\n3-) Another concept which Langchain provides is called tools. Tools are interfaces that an agent can use to interact with the outer world. We can create our own tool for Wikipedia API. In the tool specification, we can specify which function agent need to call for interaction with outer world.'), Document(metadata={'source': 'blog.txt'}, page_content='Final answer â€” actor and film producer.\\n\\nThe ReAct framework shows one way to use LLM to power an application through reasoning and action planning. We can extend this strategy to our application by creating different examples that can work through the decisions and actions that can take place in our applications.')], 'answer': \"The example in the blog demonstrates how the ReAct framework can be used to guide a language model through a reasoning process to reach a solution. In this specific example, the model is taught how to determine the number of apples left in a scenario. By structuring the examples in a way that prompts the model to think through the problem, the model successfully arrives at the correct answer of nine apples left. This approach of guiding the model through a chain of thought prompts helps improve the model's reasoning abilities for various types of problems.\"}\n",
      "\n",
      "\n",
      " The example in the blog demonstrates how the ReAct framework can be used to guide a language model through a reasoning process to reach a solution. In this specific example, the model is taught how to determine the number of apples left in a scenario. By structuring the examples in a way that prompts the model to think through the problem, the model successfully arrives at the correct answer of nine apples left. This approach of guiding the model through a chain of thought prompts helps improve the model's reasoning abilities for various types of problems.\n"
     ]
    }
   ],
   "source": [
    "# code for sample retrival\n",
    "query = 'explain me the example given in the blog'\n",
    "result = retrival_chain.invoke(input={\"input\": query})\n",
    "\n",
    "print(result)\n",
    "print('\\n\\n',result['answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['context', 'question'] template='\\nUse the following context to answer the question at the end.\\nIf you don\\'t know the answer then just say I don\\'t know the answer, dont make up any other answer.\\nUse the 3 sentence at max and keep the answer simple and short.\\nAlways say \"Let me know if you need any other help!\"\\n\\n<context>\\n{context}\\n</context>\\n\\nQuestion: {question}\\nHelpful Answer:\\n'\n"
     ]
    }
   ],
   "source": [
    "template=\"\"\"\n",
    "Use the following context to answer the question at the end.\n",
    "If you don't know the answer then just say I don't know the answer, dont make up any other answer.\n",
    "Use the 3 sentence at max and keep the answer simple and short.\n",
    "Always say \"Let me know if you need any other help!\"\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\n",
    "\"\"\"\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "custom_rag_prompt = PromptTemplate(template=template)\n",
    "print(custom_rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda\n",
    "retriever = vector_db.as_retriever()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"The example in the blog demonstrates how a language model reasons through a task to reach a solution. By structuring examples in a certain way, the model can correctly determine the answer. This approach helps improve the model's reasoning abilities for various types of problems. Let me know if you need any other help!\", response_metadata={'token_usage': {'completion_tokens': 61, 'prompt_tokens': 412, 'total_tokens': 473}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-410b21a4-b5ff-4442-8719-45c3c6c2eb00-0', usage_metadata={'input_tokens': 412, 'output_tokens': 61, 'total_tokens': 473})"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join([i.page_content for i in docs])\n",
    "\n",
    "custom_chain = {'context':retriever | format_docs, 'question':RunnablePassthrough()} | custom_rag_prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'explain me the example given in the blog'\n",
    "result = custom_chain.invoke(query)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The example in the blog demonstrates how a language model reasons through a task to reach a solution. By structuring examples in a certain way, the model can correctly determine the answer. This approach helps improve the model's reasoning abilities for various types of problems. Let me know if you need any other help!\n"
     ]
    }
   ],
   "source": [
    "print(result.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
